# Spec 032: Adaptive Retrieval Depth

**Feature**: IA decide automaticamente a profundidade de busca baseada na confiabilidade necessÃ¡ria  
**Priority**: P2 (OtimizaÃ§Ã£o MVP v1)  
**Sprint**: 2-3  
**Effort**: 4 dias  
**Status**: ðŸ“‹ Planned  

---

## VisÃ£o Geral

Sistema que permite Ã  IA **decidir autonomamente** quantos nÃ­veis de profundidade vai buscar no retrieval, baseado em:
- **Confiabilidade necessÃ¡ria** da resposta
- **Tipo de query** (factual vs estratÃ©gica)
- **Contexto disponÃ­vel** (cache vs busca nova)
- **Budget de tokens/custo**

Integra com **Spec 026 (LLM Router)** e **Spec 030 (PotÃªncia AjustÃ¡vel)**.

---

## Problema

- Sistema atual usa profundidade fixa ou escolhida pelo usuÃ¡rio
- Nem toda query precisa de busca profunda (desperdÃ­cio)
- Queries crÃ­ticas podem nÃ£o ter profundidade suficiente
- Falta mecanismo para IA auto-avaliar confiabilidade

---

## SoluÃ§Ã£o: Adaptive Retrieval

### Conceito

**IA faz 2 decisÃµes**:
1. **Antes da busca**: Estimar profundidade necessÃ¡ria
2. **ApÃ³s a busca**: Avaliar se resultado tem confiabilidade suficiente

Se confiabilidade < threshold â†’ **Buscar mais fundo automaticamente**

---

## Flow: Adaptive Retrieval

```mermaid
sequenceDiagram
    participant User
    participant LLM
    participant Retrieval
    participant VectorDB
    participant Evaluator
    
    User->>LLM: Query
    LLM->>LLM: Classifica query<br/>(factual/decision/strategic)
    
    LLM->>Retrieval: Initial depth=1 (shallow)
    Retrieval->>VectorDB: Search (3-5 chunks)
    VectorDB-->>Retrieval: Results
    
    Retrieval->>Evaluator: Avaliar confiabilidade
    Evaluator->>Evaluator: Score: 0.45 (baixo)
    
    alt Confiabilidade < 0.7 (threshold)
        Evaluator->>Retrieval: ðŸ”„ Aumentar depth=2
        Retrieval->>VectorDB: Search deeper (10-15 chunks)
        VectorDB-->>Retrieval: More results
        
        Retrieval->>Evaluator: Avaliar novamente
        Evaluator->>Evaluator: Score: 0.82 (OK)
        
        alt Ainda < 0.7
            Evaluator->>Retrieval: ðŸ”„ Aumentar depth=3 (max)
            Note over Retrieval: Budget limit atingido
        end
    end
    
    Evaluator->>LLM: Context + confidence score
    LLM->>User: Response<br/>(confidence: 0.82)
```

---

## ClassificaÃ§Ã£o de Query

### Tipos de Query (com threshold de confiabilidade)

| Tipo | Exemplos | Confidence Needed | Initial Depth |
|------|----------|-------------------|---------------|
| **Factual** | "Qual o CEO da Startup A?" | 0.9+ | 1 (shallow) |
| **Operational** | "Status do projeto X?" | 0.7+ | 1 (shallow) |
| **Decision** | "Devo investir na Startup Y?" | 0.85+ | 2 (medium) |
| **Strategic** | "AnÃ¡lise completa do portfÃ³lio" | 0.9+ | 3 (deep) |

### Regras de AdaptaÃ§Ã£o

```python
# src/services/adaptive_retrieval.py
class AdaptiveRetrieval:
    CONFIDENCE_THRESHOLDS = {
        'factual': 0.9,
        'operational': 0.7,
        'decision': 0.85,
        'strategic': 0.9
    }
    
    MAX_DEPTH = 3
    MAX_ITERATIONS = 3
    
    async def retrieve(self, query: str, query_type: str):
        threshold = self.CONFIDENCE_THRESHOLDS[query_type]
        
        # Start shallow
        depth = 1
        iterations = 0
        
        while iterations < self.MAX_ITERATIONS:
            # Retrieve at current depth
            results = await self.vector_search(query, depth)
            
            # Evaluate confidence
            confidence = await self.evaluate_confidence(query, results)
            
            # Log decision
            self.log_retrieval({
                'depth': depth,
                'chunks': len(results),
                'confidence': confidence,
                'threshold': threshold
            })
            
            # Check if sufficient
            if confidence >= threshold:
                return {
                    'results': results,
                    'confidence': confidence,
                    'depth_used': depth,
                    'iterations': iterations + 1
                }
            
            # Need more depth?
            if depth >= self.MAX_DEPTH:
                # Hit budget limit
                return {
                    'results': results,
                    'confidence': confidence,
                    'depth_used': depth,
                    'iterations': iterations + 1,
                    'warning': 'Max depth reached, confidence below threshold'
                }
            
            # Go deeper
            depth += 1
            iterations += 1
        
        # Should not reach here
        return results
```

---

## Confidence Evaluation

### Como Avaliar Confiabilidade

**MÃ©todo 1: LLM Self-Assessment**

```python
async def evaluate_confidence(self, query: str, results: list):
    """
    Pede ao LLM avaliar se os resultados sÃ£o suficientes
    """
    prompt = f"""
VocÃª tem a seguinte query:
"{query}"

E os seguintes resultados da busca:
{format_results(results)}

Avalie se vocÃª consegue responder essa query com ALTA CONFIABILIDADE baseado apenas nesses resultados.

Responda em JSON:
{{
    "confidence": 0.0-1.0,
    "reasoning": "por que esse score",
    "missing_info": ["o que falta para aumentar confianÃ§a"]
}}
"""
    
    response = await self.llm.generate(prompt)
    evaluation = json.loads(response)
    
    return evaluation['confidence']
```

**MÃ©todo 2: HeurÃ­sticas**

```python
def calculate_heuristic_confidence(self, query: str, results: list) -> float:
    """
    Calcula confianÃ§a baseado em heurÃ­sticas
    """
    scores = []
    
    # 1. Coverage: Quantos chunks relevantes?
    relevance_scores = [r['score'] for r in results]
    avg_relevance = sum(relevance_scores) / len(relevance_scores)
    scores.append(avg_relevance)
    
    # 2. Recency: QuÃ£o recente Ã© a informaÃ§Ã£o?
    now = datetime.now()
    recencies = [(now - r['created_at']).days for r in results]
    avg_recency = 1.0 / (1 + (sum(recencies) / len(recencies)) / 30)  # Decay mensal
    scores.append(avg_recency)
    
    # 3. Diversity: Fontes diferentes?
    sources = set([r['source_id'] for r in results])
    diversity = min(len(sources) / 3, 1.0)  # Ideal: 3+ fontes
    scores.append(diversity)
    
    # 4. Completeness: Query tem mÃºltiplas partes?
    query_parts = extract_query_parts(query)
    covered_parts = count_covered_parts(query_parts, results)
    completeness = covered_parts / len(query_parts)
    scores.append(completeness)
    
    # Weighted average
    weights = [0.4, 0.2, 0.2, 0.2]  # RelevÃ¢ncia Ã© mais importante
    confidence = sum(s * w for s, w in zip(scores, weights))
    
    return confidence
```

---

## Budget Limits (Evitar Loop Infinito)

### Limites de SeguranÃ§a

```python
class RetrievalBudget:
    """
    Limites para evitar busca infinita
    """
    MAX_DEPTH = 3              # NÃ£o vai alÃ©m de depth 3
    MAX_ITERATIONS = 3         # Tenta no mÃ¡ximo 3 vezes
    MAX_CHUNKS = 50            # NÃ£o retorna mais de 50 chunks
    MAX_TOKENS = 10_000        # Contexto mÃ¡ximo (tokens)
    MAX_LATENCY_MS = 5_000     # Timeout 5s
    
    def check_budget(self, current_state: dict) -> bool:
        """
        Retorna False se budget estourou
        """
        if current_state['depth'] > self.MAX_DEPTH:
            return False
        if current_state['iterations'] > self.MAX_ITERATIONS:
            return False
        if current_state['total_chunks'] > self.MAX_CHUNKS:
            return False
        if current_state['elapsed_ms'] > self.MAX_LATENCY_MS:
            return False
        
        return True
```

---

## Integration com Spec 026 (LLM Router)

### Mapping: Adaptive Depth â†” PotÃªncia

| Adaptive Depth | Context Depth (026) | PotÃªncia (030) | Chunks |
|----------------|---------------------|----------------|--------|
| 1 (shallow)    | Level 1 (Surface)   | â—â—‹â—‹ (RÃ¡pida)   | 3-5    |
| 2 (medium)     | Level 2 (Contextual)| â—â—â—‹ (Balanceada)| 10-15  |
| 3 (deep)       | Level 3 (Deep)      | â—â—â— (Profunda) | 20-40  |

**Quando usar Adaptive vs Manual**:
- **Adaptive (Auto)**: UsuÃ¡rio deixa "PotÃªncia: Auto" (Spec 030)
- **Manual**: UsuÃ¡rio forÃ§a PotÃªncia 1, 2 ou 3

```python
async def retrieve_with_mode(self, query: str, user_mode: str, user_depth: int | None):
    """
    IntegraÃ§Ã£o com modo manual (Spec 030)
    """
    if user_depth is not None:
        # UsuÃ¡rio forÃ§ou profundidade
        return await self.fixed_depth_retrieval(query, user_depth)
    
    if user_mode == 'auto':
        # Adaptive mode
        query_type = classify_query(query)
        return await self.adaptive_retrieval(query, query_type)
    
    # Default: medium depth
    return await self.fixed_depth_retrieval(query, depth=2)
```

---

## Feedback Visual (UI)

### Mostrar DecisÃ£o da IA

```
[Bot] ðŸ” Buscando informaÃ§Ãµes...

[System] âš¡ Profundidade: 1 (shallow)
         ConfianÃ§a: 0.45 (baixo)
         ðŸ”„ Aumentando para profundidade 2...

[System] âš¡ Profundidade: 2 (medium)
         ConfianÃ§a: 0.82 (OK âœ…)
         ðŸ“Š 15 chunks analisados

[Bot] Startup A apresenta os seguintes indicadores:
...

[Metadata]
ðŸ“Œ ConfianÃ§a: 82%
ðŸ“Š Profundidade usada: 2/3
â±ï¸ Tempo: 2.8s
ðŸ’° Custo: $0.03
```

---

## Metrics & Observability

### Tracking de DecisÃµes

```python
# Gravar em MongoDB
retrieval_log = {
    'query_id': uuid,
    'query': str,
    'query_type': 'decision',
    'user_mode': 'auto',
    'iterations': [
        {
            'depth': 1,
            'chunks': 5,
            'confidence': 0.45,
            'threshold': 0.85,
            'decision': 'increase_depth'
        },
        {
            'depth': 2,
            'chunks': 15,
            'confidence': 0.82,
            'threshold': 0.85,
            'decision': 'sufficient'  # Ainda abaixo, mas prÃ³ximo
        }
    ],
    'final_confidence': 0.82,
    'depth_used': 2,
    'total_chunks': 20,
    'latency_ms': 2800,
    'cost_usd': 0.03,
    'timestamp': datetime.now()
}
```

### Dashboard Metrics

```
Adaptive Retrieval Performance (Ãšltima Semana)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©dia de Depth Usada: 1.8              â”‚
â”‚ Economia vs Sempre Deep: 45%            â”‚
â”‚ Taxa de ConfianÃ§a >0.8: 89%            â”‚
â”‚ Queries que precisaram 2+ rounds: 32%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Top Queries Iterativas (precisaram depth++)
1. "AnÃ¡lise completa portfÃ³lio" â†’ 3 rounds
2. "ProjeÃ§Ã£o Q1 2025 todas startups" â†’ 3 rounds
3. "Risco de burn rate" â†’ 2 rounds
```

---

## Requisitos Funcionais

### RF-AR-001: ClassificaÃ§Ã£o AutomÃ¡tica
- Sistema DEVE classificar query em um dos 4 tipos
- Cada tipo DEVE ter threshold de confiabilidade definido

### RF-AR-002: AvaliaÃ§Ã£o de Confiabilidade
- Sistema DEVE avaliar confianÃ§a apÃ³s cada retrieval
- DEVE usar LLM self-assessment OU heurÃ­sticas
- Score DEVE ser 0.0-1.0

### RF-AR-003: AdaptaÃ§Ã£o Iterativa
- Se confidence < threshold â†’ aumentar depth
- MÃ¡ximo de 3 iteraÃ§Ãµes (budget limit)
- Log de cada decisÃ£o

### RF-AR-004: Budget Limits
- DEVE respeitar MAX_DEPTH=3
- DEVE respeitar MAX_ITERATIONS=3
- DEVE timeout apÃ³s 5s

### RF-AR-005: Feedback Visual
- Mostrar profundidade usada
- Mostrar score de confianÃ§a
- Mostrar quantas iteraÃ§Ãµes

### RF-AR-006: Integration Manual Mode
- Respeitar PotÃªncia manual (Spec 030)
- Adaptive APENAS se modo Auto

---

## User Scenarios

### Scenario 1: Query Simples (1 round suficiente)

```
[User] "Qual o CEO da Startup A?"

[System] 
- Classifica: factual (threshold 0.9)
- Depth 1 (3 chunks)
- Confidence: 0.95 âœ…
- Responde imediatamente

[Bot] "O CEO da Startup A Ã© Ana Oliveira."
ðŸ“Œ ConfianÃ§a: 95% | Depth: 1/3 | 0.8s
```

### Scenario 2: Query Complexa (3 rounds)

```
[User] "AnÃ¡lise completa de risco do portfÃ³lio"

[System]
- Classifica: strategic (threshold 0.9)
- Round 1: Depth 1 â†’ Confidence 0.52 âŒ
- Round 2: Depth 2 â†’ Confidence 0.73 âš ï¸
- Round 3: Depth 3 â†’ Confidence 0.88 âœ…
- Budget limit (depth 3)

[Bot] [AnÃ¡lise detalhada com 40 chunks]
ðŸ“Œ ConfianÃ§a: 88% | Depth: 3/3 | 8.2s
âš ï¸ Confidence abaixo do ideal (90%), mas max depth atingido
```

### Scenario 3: UsuÃ¡rio Force PotÃªncia (Override)

```
[User] Seleciona PotÃªncia 1 manual
[User] "AnÃ¡lise de risco do portfÃ³lio"

[System]
- Ignora adaptive (usuÃ¡rio forÃ§ou)
- Usa depth 1 fixo
- Confidence: 0.52 (baixo, mas respeitando user)

[Bot] [Resposta breve]
ðŸ“Œ ConfianÃ§a: 52% | Depth: 1/3 (manual) | 1.2s
ðŸ’¡ SugestÃ£o: Use PotÃªncia 2 ou Auto para anÃ¡lise mais completa
```

---

## MÃ©tricas de Sucesso

- âœ… Economia de custo: 40%+ vs sempre usar depth 3
- âœ… ConfianÃ§a mÃ©dia: >0.8
- âœ… LatÃªncia: <5s mesmo com mÃºltiplas iteraÃ§Ãµes
- âœ… Taxa de satisfaÃ§Ã£o: UsuÃ¡rio valida se resposta foi suficiente

---

## Dependencies

| Spec | Dependency | Reason |
|------|------------|--------|
| 026 | **MUST** | LLM Router + Context Depth (base tÃ©cnica) |
| 030 | **SHOULD** | PotÃªncia manual (override adaptive) |
| 001 | **SHOULD** | Knowledge Pipeline (vector search) |

---

## Implementation Notes

### Phase 1: ClassificaÃ§Ã£o + HeurÃ­stica (2d)
- Query classifier
- Heuristic confidence calculation
- Budget limits

### Phase 2: LLM Self-Assessment (1d)
- Prompt para LLM avaliar confianÃ§a
- JSON parsing

### Phase 3: Adaptive Loop (1d)
- IteraÃ§Ã£o depth++
- Logging de decisÃµes
- Integration com Spec 026/030

---

## Testing Strategy

```python
def test_adaptive_retrieval():
    # Test 1: Simple query (1 round)
    result = await adaptive.retrieve("Qual o CEO?", "factual")
    assert result['depth_used'] == 1
    assert result['confidence'] >= 0.9
    
    # Test 2: Complex query (multiple rounds)
    result = await adaptive.retrieve("AnÃ¡lise completa", "strategic")
    assert result['iterations'] > 1
    assert result['confidence'] >= 0.85 or result['depth_used'] == 3
    
    # Test 3: Budget limit
    result = await adaptive.retrieve("Query impossÃ­vel", "strategic")
    assert result['iterations'] <= 3
    assert result['depth_used'] <= 3
```

---

**Status**: ðŸ“‹ Planned (Sprint 2-3)  
**Next**: Implementar apÃ³s Spec 026 (LLM Router)
